{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating point data for non-landslide locations \n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr\n",
    "import random\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script used to create Non-landslide points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landslide points and fishnet\n",
    "\n",
    "landslides = gpd.read_file('Q:\\\\Endelige Vektordata\\\\Landslide_50%roads_removed.shp')\n",
    "fishnet = gpd.read_file('Q:\\\\Endelige Vektordata\\\\Fishnet_40_Training_PartsRemoved.shp')\n",
    "\n",
    "# External Validation\n",
    "\n",
    "#landslides = gpd.read_file('Q:\\\\Endelige Vektordata\\\\ExVal_Landslide_50%roads_removed.shp')\n",
    "#fishnet = gpd.read_file('Q:\\\\Endelige Vektordata\\\\Fishnet_40_ExternalValidation.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-landslide points generated and saved as Shapefile.\n"
     ]
    }
   ],
   "source": [
    "# Buffer the landslide points by 120 meters\n",
    "buffered_landslides = landslides.buffer(120)\n",
    "\n",
    "# Exclude grid cells that intersect with buffered landslide points\n",
    "exclusion_zone = buffered_landslides.unary_union\n",
    "candidate_cells = fishnet[~fishnet.intersects(exclusion_zone)]\n",
    "\n",
    "selected_cells = candidate_cells.sample(n=len(landslides))# equal to number of points in 'landslides' point data\n",
    "\n",
    "# Generate a random point within each selected cell\n",
    "def generate_random_point_in_cell(cell):\n",
    "    minx, miny, maxx, maxy = cell.bounds\n",
    "    while True:\n",
    "        random_point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if random_point.within(cell):\n",
    "            return random_point\n",
    "\n",
    "non_landslide_points = selected_cells.geometry.apply(generate_random_point_in_cell)\n",
    "\n",
    "non_landslide_gdf = gpd.GeoDataFrame(geometry=non_landslide_points)\n",
    "non_landslide_gdf.to_file('Q:\\\\Endelige Vektordata\\\\Non_landslides_50%roadsremoved_2.shp', driver='ESRI Shapefile')\n",
    "print('Non-landslide points generated and saved as Shapefile.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining landslide and non-landslide shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_landslide = gpd.read_file('Q:\\\\Endelige Vektordata\\\\Non_landslides_50%roadsremoved_2.shp')\n",
    "# populate with the target variable\n",
    "non_landslide['Landslide'] = 0\n",
    "\n",
    "non_landslide.to_file('Q:\\\\Endelige Vektordata\\\\Non_landslides_50%roadsremoved_2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide = gpd.read_file('Q:\\\\Endelige Vektordata\\\\Landslide_50%roadsremoved_w_landslidedata.shp')\n",
    "#landslide['Landslide'] = 1\n",
    "#landslide.to_file('Q:\\\\Endelige Vektordata\\\\ExVal_Landslide_50%roads_removed.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine geodataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_crs = 'epsg:25833'\n",
    "non_landslide = non_landslide.to_crs(common_crs)\n",
    "landslide = landslide.to_crs(common_crs)\n",
    "\n",
    "combined = pd.concat([non_landslide, landslide], ignore_index=True)\n",
    "\n",
    "combined.to_file('Q:\\\\Endelige Vektordata\\\\Landslide_non_landslide_50%roadsremoved_2.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the CSV file for ML training (proceed after data sampling, when the points is populated with values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = gpd.read_file('E:\\\\LSM - NGU metode\\\\Landslide_non_landslide_NGU_metode_Training.shp')\n",
    "trainingdata.to_csv(\"E:\\\\LSM - NGU metode\\\\TrainingData_NGU_method.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exvalidationdata = gpd.read_file('E:\\\\LSM - NGU metode\\\\Landslide_non_landslide_NGU_metode_External.shp')\n",
    "exvalidationdata.to_csv(\"E:\\\\LSM - NGU metode\\\\ExternalValidation_NGU_method.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZonalStpip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
